#!/usr/bin/env python3
"""
ä½¿ç”¨ SORT è¿½è¸ªå™¨é‡æ–°å¤„ç†å·²æœ‰çš„æ£€æµ‹ç»“æœ
å°†æ•£ä¹±çš„æ£€æµ‹æ¡†é‡æ–°å…³è”ï¼Œåˆå¹¶ä¸ºç¨³å®šçš„è½¨è¿¹

ç”¨æ³•:
    python3 scripts/retrack_with_sort.py \
        SAM3_output/clip_000_every_frame.json \
        --output SAM3_output/clip_000_sort_retracked.json \
        --video data/D1_video_clips/D1_rand11-15_clip_000.mp4
"""

import os
import sys
import json
import argparse
import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Optional
from collections import defaultdict

# SORT è¿½è¸ªå™¨ä¾èµ–
try:
    from filterpy.kalman import KalmanFilter
    from scipy.optimize import linear_sum_assignment
    SORT_AVAILABLE = True
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£…ä¾èµ–: pip install filterpy scipy")
    sys.exit(1)

# é¢œè‰²åˆ—è¡¨ï¼ˆBGRæ ¼å¼ï¼‰ç”¨äºå¯è§†åŒ–
COLORS = [
    (0, 255, 0),    # ç»¿è‰²
    (255, 0, 0),    # è“è‰²
    (0, 0, 255),    # çº¢è‰²
    (255, 255, 0),  # é’è‰²
    (255, 0, 255),  # ç´«è‰²
    (0, 255, 255),  # é»„è‰²
    (128, 255, 0),  # æµ…ç»¿
    (255, 128, 0),  # æµ…è“
    (128, 0, 255),  # ç²‰è‰²
    (0, 128, 255),  # æ©™è‰²
]


def calculate_iou(box1, box2):
    """è®¡ç®—ä¸¤ä¸ªæ¡†çš„ IoU"""
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    
    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0


class KalmanBoxTracker:
    """ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢è¿½è¸ªå•ä¸ªç›®æ ‡çš„è¾¹ç•Œæ¡†"""
    count = 0
    
    def __init__(self, bbox, label, score=1.0):
        self.kf = KalmanFilter(dim_x=7, dim_z=4)
        
        # çŠ¶æ€è½¬ç§»çŸ©é˜µ
        self.kf.F = np.array([
            [1, 0, 0, 0, 1, 0, 0],
            [0, 1, 0, 0, 0, 1, 0],
            [0, 0, 1, 0, 0, 0, 1],
            [0, 0, 0, 1, 0, 0, 0],
            [0, 0, 0, 0, 1, 0, 0],
            [0, 0, 0, 0, 0, 1, 0],
            [0, 0, 0, 0, 0, 0, 1]
        ])
        
        # è§‚æµ‹çŸ©é˜µ
        self.kf.H = np.array([
            [1, 0, 0, 0, 0, 0, 0],
            [0, 1, 0, 0, 0, 0, 0],
            [0, 0, 1, 0, 0, 0, 0],
            [0, 0, 0, 1, 0, 0, 0]
        ])
        
        # å™ªå£°å‚æ•°
        self.kf.R[2:, 2:] *= 10.
        self.kf.P[4:, 4:] *= 1000.
        self.kf.P *= 10.
        self.kf.Q[-1, -1] *= 0.01
        self.kf.Q[4:, 4:] *= 0.01
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.kf.x[:4] = self._bbox_to_z(bbox)
        
        self.time_since_update = 0
        self.id = KalmanBoxTracker.count
        KalmanBoxTracker.count += 1
        self.history = []
        self.hits = 0
        self.hit_streak = 0
        self.age = 0
        self.label = label
        self.score = score
    
    @staticmethod
    def _bbox_to_z(bbox):
        w = bbox[2] - bbox[0]
        h = bbox[3] - bbox[1]
        x = bbox[0] + w / 2.
        y = bbox[1] + h / 2.
        s = w * h
        r = w / float(h) if h > 0 else 1.0
        return np.array([x, y, s, r]).reshape((4, 1))
    
    @staticmethod
    def _z_to_bbox(z):
        w = np.sqrt(z[2] * z[3])
        h = z[2] / w if w > 0 else 0
        return np.array([
            z[0] - w / 2.,
            z[1] - h / 2.,
            z[0] + w / 2.,
            z[1] + h / 2.
        ]).flatten()
    
    def update(self, bbox, score=None):
        self.time_since_update = 0
        self.history = []
        self.hits += 1
        self.hit_streak += 1
        self.kf.update(self._bbox_to_z(bbox))
        if score is not None:
            self.score = score
    
    def predict(self):
        if (self.kf.x[6] + self.kf.x[2]) <= 0:
            self.kf.x[6] *= 0.0
        self.kf.predict()
        self.age += 1
        if self.time_since_update > 0:
            self.hit_streak = 0
        self.time_since_update += 1
        self.history.append(self._z_to_bbox(self.kf.x))
        return self.history[-1]
    
    def get_state(self):
        return self._z_to_bbox(self.kf.x)


class SORTTracker:
    """SORT è¿½è¸ªå™¨"""
    
    def __init__(self, max_age=30, min_hits=3, iou_threshold=0.3):
        self.max_age = max_age
        self.min_hits = min_hits
        self.iou_threshold = iou_threshold
        self.trackers = []
        self.frame_count = 0
    
    def update(self, detections):
        """
        Args:
            detections: [(label, box, score), ...]
        Returns:
            tracks: [(label, box, track_id, score), ...]
        """
        self.frame_count += 1
        
        # é¢„æµ‹æ‰€æœ‰ç°æœ‰è½¨è¿¹
        for trk in self.trackers:
            trk.predict()
        
        # åˆ é™¤æ— æ•ˆè½¨è¿¹
        self.trackers = [t for t in self.trackers if not np.any(np.isnan(t.get_state()))]
        
        # åŒ¹é…æ£€æµ‹å’Œè½¨è¿¹
        matched, unmatched_dets, _ = self._associate(detections)
        
        # æ›´æ–°åŒ¹é…çš„è½¨è¿¹
        for d, t in matched:
            label, box, score = detections[d]
            self.trackers[t].update(box, score)
        
        # ä¸ºæœªåŒ¹é…çš„æ£€æµ‹åˆ›å»ºæ–°è½¨è¿¹
        for d in unmatched_dets:
            label, box, score = detections[d]
            self.trackers.append(KalmanBoxTracker(box, label, score))
        
        # è¿”å›æœ‰æ•ˆè½¨è¿¹
        ret = []
        i = len(self.trackers)
        for trk in reversed(self.trackers):
            d = trk.get_state()
            if (trk.time_since_update < 1) and \
               (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):
                ret.append((trk.label, tuple(d), trk.id, trk.score))
            i -= 1
            if trk.time_since_update > self.max_age:
                self.trackers.pop(i)
        
        return ret
    
    def _associate(self, detections):
        if len(self.trackers) == 0:
            return [], list(range(len(detections))), []
        
        if len(detections) == 0:
            return [], [], list(range(len(self.trackers)))
        
        # æ„å»º IoU çŸ©é˜µ
        iou_matrix = np.zeros((len(detections), len(self.trackers)))
        for d, det in enumerate(detections):
            det_label, det_box, _ = det
            for t, trk in enumerate(self.trackers):
                if det_label == trk.label:
                    iou_matrix[d, t] = calculate_iou(det_box, trk.get_state())
        
        # åŒˆç‰™åˆ©ç®—æ³•
        row_indices, col_indices = linear_sum_assignment(-iou_matrix)
        matched_indices = list(zip(row_indices, col_indices))
        
        unmatched_dets = [d for d in range(len(detections)) 
                         if d not in [m[0] for m in matched_indices]]
        unmatched_trks = [t for t in range(len(self.trackers)) 
                         if t not in [m[1] for m in matched_indices]]
        
        # è¿‡æ»¤ä½ IoU åŒ¹é…
        matches = []
        for d, t in matched_indices:
            if iou_matrix[d, t] < self.iou_threshold:
                unmatched_dets.append(d)
                unmatched_trks.append(t)
            else:
                matches.append((d, t))
        
        return matches, unmatched_dets, unmatched_trks


def load_detections_from_json(json_path: str) -> Dict[int, List]:
    """
    ä» Label Studio JSON æ ¼å¼åŠ è½½æ£€æµ‹ç»“æœ
    
    Returns:
        {frame_idx: [(label, box, score), ...], ...}
    """
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    detections_by_frame = defaultdict(list)
    
    # éå†æ‰€æœ‰æ ‡æ³¨ç»“æœ
    for item in data:
        predictions = item.get("predictions", [])
        for pred in predictions:
            results = pred.get("result", [])
            for result in results:
                if result.get("type") != "videorectangle":
                    continue
                
                value = result.get("value", {})
                labels = value.get("labels", [])
                label = labels[0] if labels else "unknown"
                sequence = value.get("sequence", [])
                
                for frame_data in sequence:
                    frame_idx = frame_data.get("frame", 0)
                    # ç™¾åˆ†æ¯”åæ ‡ (0-100)
                    x = frame_data.get("x", 0)
                    y = frame_data.get("y", 0)
                    w = frame_data.get("width", 0)
                    h = frame_data.get("height", 0)
                    
                    # å­˜å‚¨ä¸ºç™¾åˆ†æ¯”æ ¼å¼çš„ box (x1, y1, x2, y2)
                    box = (x, y, x + w, y + h)
                    score = frame_data.get("score", 0.5) if "score" in frame_data else 0.5
                    
                    detections_by_frame[frame_idx].append((label, box, score))
    
    return dict(detections_by_frame)


def draw_box_on_frame(frame, x1, y1, x2, y2, label, obj_id, color):
    """åœ¨å¸§ä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†"""
    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
    
    text = f"{label} #{obj_id}"
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.5
    thickness = 1
    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
    
    cv2.rectangle(frame, (x1, y1 - text_height - 6), (x1 + text_width + 6, y1), color, -1)
    cv2.putText(frame, text, (x1 + 3, y1 - 3), font, font_scale, (255, 255, 255), thickness)
    
    return frame


def retrack_with_sort(
    input_json: str,
    output_json: str,
    video_path: str = None,
    max_age: int = 30,
    min_hits: int = 3,
    iou_threshold: float = 0.3,
    generate_video: bool = True,
    debug: bool = False
):
    """
    ä½¿ç”¨ SORT é‡æ–°è¿½è¸ªå·²æœ‰çš„æ£€æµ‹ç»“æœ
    """
    print(f"ğŸ“‚ åŠ è½½æ£€æµ‹ç»“æœ: {input_json}")
    detections_by_frame = load_detections_from_json(input_json)
    
    if not detections_by_frame:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ£€æµ‹ç»“æœ")
        return
    
    frame_indices = sorted(detections_by_frame.keys())
    max_frame = max(frame_indices)
    total_detections = sum(len(d) for d in detections_by_frame.values())
    
    print(f"   å¸§èŒƒå›´: {min(frame_indices)} - {max_frame}")
    print(f"   æ€»æ£€æµ‹æ•°: {total_detections}")
    
    # è·å–è§†é¢‘ä¿¡æ¯
    width, height, fps = 1920, 1080, 25.0
    video_writer = None
    cap = None
    
    if video_path and os.path.exists(video_path):
        cap = cv2.VideoCapture(video_path)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        print(f"ğŸ“¹ è§†é¢‘ä¿¡æ¯: {width}x{height} @ {fps:.1f}fps")
    
    # åˆå§‹åŒ– SORT è¿½è¸ªå™¨
    # é‡ç½® KalmanBoxTracker è®¡æ•°å™¨
    KalmanBoxTracker.count = 0
    
    tracker = SORTTracker(
        max_age=max_age,
        min_hits=min_hits,
        iou_threshold=iou_threshold
    )
    
    print(f"ğŸ”„ ä½¿ç”¨ SORT è¿½è¸ªå™¨")
    print(f"   å‚æ•°: max_age={max_age}, min_hits={min_hits}, iou_threshold={iou_threshold}")
    
    # å‡†å¤‡è¾“å‡ºè§†é¢‘
    temp_video_path = None
    video_output_path = None
    if generate_video and cap is not None:
        video_output_path = output_json.replace('.json', '_annotated.mp4')
        temp_video_path = output_json.replace('.json', '_temp.avi')
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        video_writer = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))
    
    # å­˜å‚¨è¿½è¸ªç»“æœ
    all_tracks = {}  # {track_id: {"label": str, "frames": {frame_idx: box_data}}}
    
    print(f"ğŸ”„ å¤„ç†å¸§...")
    
    for frame_idx in range(max_frame + 1):
        # è·å–å½“å‰å¸§çš„æ£€æµ‹
        detections = detections_by_frame.get(frame_idx, [])
        
        # å°†ç™¾åˆ†æ¯”åæ ‡è½¬æ¢ä¸ºåƒç´ åæ ‡ï¼ˆç”¨äºè¿½è¸ªï¼‰
        pixel_detections = []
        for label, box, score in detections:
            x1, y1, x2, y2 = box
            px1 = x1 / 100 * width
            py1 = y1 / 100 * height
            px2 = x2 / 100 * width
            py2 = y2 / 100 * height
            pixel_detections.append((label, (px1, py1, px2, py2), score))
        
        # æ›´æ–°è¿½è¸ªå™¨
        tracks = tracker.update(pixel_detections)
        
        if debug and tracks:
            print(f"   [å¸§ {frame_idx}] æ£€æµ‹: {len(detections)}, è¿½è¸ª: {len(tracks)}")
        
        # ä¿å­˜è¿½è¸ªç»“æœ
        frame_annotations = []
        for label, box, track_id, score in tracks:
            x1, y1, x2, y2 = box
            
            if track_id not in all_tracks:
                all_tracks[track_id] = {
                    "label": label,
                    "frames": {}
                }
            
            # è½¬æ¢å›ç™¾åˆ†æ¯”
            box_data = {
                "x": x1 / width * 100,
                "y": y1 / height * 100,
                "width": (x2 - x1) / width * 100,
                "height": (y2 - y1) / height * 100,
                "time": frame_idx / fps
            }
            all_tracks[track_id]["frames"][frame_idx] = box_data
            
            frame_annotations.append({
                "label": label,
                "obj_id": track_id,
                "pixel_box": (int(x1), int(y1), int(x2), int(y2)),
                "color": COLORS[track_id % len(COLORS)]
            })
        
        # ç”Ÿæˆè§†é¢‘å¸§
        if video_writer is not None and cap is not None:
            ret, frame = cap.read()
            if ret:
                for ann in frame_annotations:
                    x1, y1, x2, y2 = ann["pixel_box"]
                    frame = draw_box_on_frame(
                        frame, x1, y1, x2, y2,
                        ann["label"], ann["obj_id"], ann["color"]
                    )
                
                cv2.putText(frame, f"Frame: {frame_idx} [SORT]", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                video_writer.write(frame)
        
        if frame_idx % 50 == 0:
            print(f"   å·²å¤„ç† {frame_idx}/{max_frame} å¸§")
    
    if cap is not None:
        cap.release()
    if video_writer is not None:
        video_writer.release()
        
        # ä½¿ç”¨ ffmpeg ä¼˜åŒ–ç¼–ç 
        if temp_video_path and os.path.exists(temp_video_path):
            print("ğŸ”„ æ­£åœ¨ä¼˜åŒ–è§†é¢‘ç¼–ç ...")
            import subprocess
            try:
                cmd = [
                    'ffmpeg', '-y', '-i', temp_video_path,
                    '-c:v', 'libx264', '-preset', 'fast', '-crf', '23',
                    '-pix_fmt', 'yuv420p',
                    video_output_path
                ]
                subprocess.run(cmd, capture_output=True, check=True)
                os.remove(temp_video_path)
                print("   è§†é¢‘ç¼–ç ä¼˜åŒ–å®Œæˆ")
            except (subprocess.CalledProcessError, FileNotFoundError):
                import shutil
                shutil.move(temp_video_path, video_output_path)
    
    # è½¬æ¢ä¸º Label Studio æ ¼å¼
    ls_results = []
    for track_id, track_data in all_tracks.items():
        frames_data = track_data["frames"]
        if not frames_data:
            continue
        
        sequence = []
        for fidx, data in sorted(frames_data.items()):
            sequence.append({
                "frame": fidx,
                "x": data["x"],
                "y": data["y"],
                "width": data["width"],
                "height": data["height"],
                "rotation": 0,
                "time": data["time"],
                "enabled": True
            })
        
        if sequence:
            ls_results.append({
                "from_name": "box",
                "to_name": "video",
                "type": "videorectangle",
                "value": {
                    "sequence": sequence,
                    "labels": [track_data["label"]]
                },
                "id": f"track_{track_id}"
            })
    
    # ä¿å­˜ JSON ç»“æœ
    output_data = [{
        "data": {
            "video": f"/data/local-files/?d={os.path.basename(video_path) if video_path else 'video.mp4'}"
        },
        "predictions": [{
            "result": ls_results,
            "model_version": "SORT-Retracked"
        }]
    }]
    
    os.makedirs(os.path.dirname(os.path.abspath(output_json)), exist_ok=True)
    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    # ç»Ÿè®¡
    print(f"\nâœ… è¿½è¸ªå®Œæˆ!")
    print(f"   åŸå§‹æ£€æµ‹: {total_detections} ä¸ªæ¡†")
    print(f"   åˆå¹¶è½¨è¿¹: {len(ls_results)} æ¡")
    print(f"   JSON ä¿å­˜åˆ°: {output_json}")
    
    if video_output_path:
        print(f"   è§†é¢‘ä¿å­˜åˆ°: {video_output_path}")
    
    # æ˜¾ç¤ºæ¯ä¸ªè½¨è¿¹çš„ä¿¡æ¯
    print(f"\nğŸ“Š è½¨è¿¹è¯¦æƒ…:")
    label_counts = defaultdict(int)
    for track_id, track_data in all_tracks.items():
        label = track_data["label"]
        frame_count = len(track_data["frames"])
        label_counts[label] += 1
        if debug:
            frames = sorted(track_data["frames"].keys())
            print(f"   Track #{track_id} [{label}]: {frame_count} å¸§ (å¸§ {frames[0]}-{frames[-1]})")
    
    for label, count in sorted(label_counts.items()):
        print(f"   - {label}: {count} ä¸ªç›®æ ‡")


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ SORT è¿½è¸ªå™¨é‡æ–°å¤„ç†æ£€æµ‹ç»“æœ"
    )
    parser.add_argument(
        "input_json",
        help="è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„ï¼ˆLabel Studio æ ¼å¼ï¼‰"
    )
    parser.add_argument(
        "--output", "-o",
        default=None,
        help="è¾“å‡º JSON è·¯å¾„ï¼ˆé»˜è®¤: è¾“å…¥æ–‡ä»¶å_sort.jsonï¼‰"
    )
    parser.add_argument(
        "--video", "-v",
        default=None,
        help="åŸå§‹è§†é¢‘è·¯å¾„ï¼ˆç”¨äºç”Ÿæˆæ ‡æ³¨è§†é¢‘ï¼‰"
    )
    parser.add_argument(
        "--max-age",
        type=int,
        default=30,
        help="ç›®æ ‡ä¸¢å¤±åä¿ç•™çš„æœ€å¤§å¸§æ•°ï¼ˆé»˜è®¤: 30ï¼‰"
    )
    parser.add_argument(
        "--min-hits",
        type=int,
        default=3,
        help="è¿ç»­å‘½ä¸­å¤šå°‘æ¬¡æ‰ç®—æœ‰æ•ˆè½¨è¿¹ï¼ˆé»˜è®¤: 3ï¼‰"
    )
    parser.add_argument(
        "--iou-threshold",
        type=float,
        default=0.3,
        help="IoU åŒ¹é…é˜ˆå€¼ï¼ˆé»˜è®¤: 0.3ï¼‰"
    )
    parser.add_argument(
        "--no-video",
        action="store_true",
        help="ä¸ç”Ÿæˆæ ‡æ³¨è§†é¢‘"
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†è°ƒè¯•ä¿¡æ¯"
    )
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input_json):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_json}")
        sys.exit(1)
    
    if args.output is None:
        args.output = args.input_json.replace('.json', '_sort.json')
    
    retrack_with_sort(
        input_json=args.input_json,
        output_json=args.output,
        video_path=args.video,
        max_age=args.max_age,
        min_hits=args.min_hits,
        iou_threshold=args.iou_threshold,
        generate_video=not args.no_video,
        debug=args.debug
    )


if __name__ == "__main__":
    main()





