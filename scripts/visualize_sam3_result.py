#!/usr/bin/env python3
"""
å¯è§†åŒ– SAM3 è¿½è¸ªç»“æœ
å°† JSON æ ‡æ³¨ç»“æœå åŠ åˆ°è§†é¢‘ä¸Šï¼Œç”Ÿæˆå¸¦è¾¹ç•Œæ¡†çš„è§†é¢‘
"""

import os
import sys
import json
import argparse
import cv2
import numpy as np
from collections import defaultdict

# é¢œè‰²åˆ—è¡¨ï¼ˆBGRæ ¼å¼ï¼‰
COLORS = [
    (0, 255, 0),    # ç»¿è‰²
    (255, 0, 0),    # è“è‰²
    (0, 0, 255),    # çº¢è‰²
    (255, 255, 0),  # é’è‰²
    (255, 0, 255),  # ç´«è‰²
    (0, 255, 255),  # é»„è‰²
    (128, 255, 0),  # æµ…ç»¿
    (255, 128, 0),  # æµ…è“
    (128, 0, 255),  # ç²‰è‰²
    (0, 128, 255),  # æ©™è‰²
]


def load_annotations(json_path: str) -> dict:
    """åŠ è½½ JSON æ ‡æ³¨æ–‡ä»¶"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # è§£ææ ‡æ³¨ç»“æœ
    annotations = defaultdict(list)  # {frame_idx: [(box, label, obj_id, color), ...]}
    
    if isinstance(data, list) and len(data) > 0:
        predictions = data[0].get("predictions", [])
        if predictions:
            results = predictions[0].get("result", [])
            
            for idx, result in enumerate(results):
                obj_id = result.get("id", f"obj_{idx}")
                value = result.get("value", {})
                labels = value.get("labels", ["object"])
                label = labels[0] if labels else "object"
                sequence = value.get("sequence", [])
                
                color = COLORS[idx % len(COLORS)]
                
                for frame_data in sequence:
                    frame_idx = frame_data.get("frame", 0)
                    x = frame_data.get("x", 0)
                    y = frame_data.get("y", 0)
                    width = frame_data.get("width", 0)
                    height = frame_data.get("height", 0)
                    
                    annotations[frame_idx].append({
                        "x": x,
                        "y": y,
                        "width": width,
                        "height": height,
                        "label": label,
                        "obj_id": obj_id,
                        "color": color
                    })
    
    return annotations


def draw_box(frame, box_data, frame_width, frame_height):
    """åœ¨å¸§ä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†"""
    # åæ ‡æ˜¯ç™¾åˆ†æ¯” (0-100)ï¼Œè½¬æ¢ä¸ºåƒç´ 
    x_pct = box_data["x"]
    y_pct = box_data["y"]
    w_pct = box_data["width"]
    h_pct = box_data["height"]
    
    # æ£€æŸ¥åæ ‡æ˜¯å¦åˆç†ï¼ˆåº”è¯¥åœ¨ 0-100 èŒƒå›´å†…ï¼‰
    # å¦‚æœåæ ‡å€¼å¤ªå¤§ï¼Œå¯èƒ½æ˜¯åƒç´ åæ ‡ï¼Œéœ€è¦å½’ä¸€åŒ–
    if x_pct > 100 or y_pct > 100 or w_pct > 100 or h_pct > 100:
        # å‡è®¾æ˜¯åƒç´ åæ ‡ï¼Œç›´æ¥ä½¿ç”¨
        x1 = int(x_pct)
        y1 = int(y_pct)
        x2 = int(x_pct + w_pct)
        y2 = int(y_pct + h_pct)
        
        # ä½†å¦‚æœè¿˜æ˜¯å¤ªå¤§ï¼Œå¯èƒ½éœ€è¦ç¼©æ”¾
        if x2 > frame_width * 10 or y2 > frame_height * 10:
            # å¯èƒ½æ˜¯ä¹˜ä»¥äº†å›¾åƒå°ºå¯¸ï¼Œéœ€è¦é™¤å›å»
            scale_x = frame_width
            scale_y = frame_height
            x1 = int(x_pct / scale_x * frame_width / 100)
            y1 = int(y_pct / scale_y * frame_height / 100)
            x2 = int((x_pct + w_pct) / scale_x * frame_width / 100)
            y2 = int((y_pct + h_pct) / scale_y * frame_height / 100)
    else:
        # æ­£å¸¸çš„ç™¾åˆ†æ¯”åæ ‡
        x1 = int(x_pct / 100 * frame_width)
        y1 = int(y_pct / 100 * frame_height)
        x2 = int((x_pct + w_pct) / 100 * frame_width)
        y2 = int((y_pct + h_pct) / 100 * frame_height)
    
    # ç¡®ä¿åæ ‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
    x1 = max(0, min(x1, frame_width - 1))
    y1 = max(0, min(y1, frame_height - 1))
    x2 = max(0, min(x2, frame_width))
    y2 = max(0, min(y2, frame_height))
    
    color = box_data["color"]
    label = box_data["label"]
    obj_id = box_data["obj_id"]
    
    # ç»˜åˆ¶è¾¹ç•Œæ¡†
    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
    
    # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
    text = f"{label} ({obj_id})"
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.6
    thickness = 2
    (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
    
    cv2.rectangle(frame, (x1, y1 - text_height - 10), (x1 + text_width + 10, y1), color, -1)
    cv2.putText(frame, text, (x1 + 5, y1 - 5), font, font_scale, (255, 255, 255), thickness)
    
    return frame


def visualize_video(video_path: str, json_path: str, output_path: str):
    """ç”Ÿæˆå¸¦æ ‡æ³¨çš„è§†é¢‘"""
    print(f"ğŸ“¹ åŠ è½½è§†é¢‘: {video_path}")
    print(f"ğŸ“ åŠ è½½æ ‡æ³¨: {json_path}")
    
    # åŠ è½½æ ‡æ³¨
    annotations = load_annotations(json_path)
    print(f"   å…±æœ‰ {len(annotations)} å¸§æœ‰æ ‡æ³¨")
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print(f"   è§†é¢‘ä¿¡æ¯: {frame_width}x{frame_height}, {fps}fps, {frame_count}å¸§")
    
    # åˆ›å»ºè¾“å‡ºè§†é¢‘
    os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))
    
    frame_idx = 0
    annotated_frames = 0
    
    print(f"ğŸ¬ ç”Ÿæˆæ ‡æ³¨è§†é¢‘...")
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # å¦‚æœå½“å‰å¸§æœ‰æ ‡æ³¨ï¼Œç»˜åˆ¶è¾¹ç•Œæ¡†
        if frame_idx in annotations:
            for box_data in annotations[frame_idx]:
                frame = draw_box(frame, box_data, frame_width, frame_height)
            annotated_frames += 1
        
        # åœ¨å·¦ä¸Šè§’æ˜¾ç¤ºå¸§å·
        cv2.putText(frame, f"Frame: {frame_idx}", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        out.write(frame)
        frame_idx += 1
        
        if frame_idx % 100 == 0:
            print(f"   å·²å¤„ç† {frame_idx}/{frame_count} å¸§...")
    
    cap.release()
    out.release()
    
    print(f"âœ… æ ‡æ³¨è§†é¢‘å·²ä¿å­˜åˆ°: {output_path}")
    print(f"   å…±æ ‡æ³¨äº† {annotated_frames} å¸§")


def main():
    parser = argparse.ArgumentParser(description="å¯è§†åŒ– SAM3 è¿½è¸ªç»“æœ")
    parser.add_argument("video_path", help="åŸå§‹è§†é¢‘è·¯å¾„")
    parser.add_argument("json_path", help="JSON æ ‡æ³¨æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--output", "-o",
        default=None,
        help="è¾“å‡ºè§†é¢‘è·¯å¾„ (é»˜è®¤: åœ¨ JSON åŒç›®å½•ä¸‹ç”Ÿæˆ)"
    )
    
    args = parser.parse_args()
    
    if not os.path.exists(args.video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video_path}")
        sys.exit(1)
    
    if not os.path.exists(args.json_path):
        print(f"âŒ JSON æ–‡ä»¶ä¸å­˜åœ¨: {args.json_path}")
        sys.exit(1)
    
    if args.output is None:
        # é»˜è®¤è¾“å‡ºè·¯å¾„
        json_dir = os.path.dirname(args.json_path)
        json_name = os.path.splitext(os.path.basename(args.json_path))[0]
        args.output = os.path.join(json_dir, f"{json_name}_annotated.mp4")
    
    visualize_video(args.video_path, args.json_path, args.output)


if __name__ == "__main__":
    main()








