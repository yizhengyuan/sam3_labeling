#!/usr/bin/env python3
"""
é›†æˆäº¤é€šæ ‡å¿—æ£€æµ‹ä¸SAM3è¿½è¸ªæµæ°´çº¿
ç»“åˆæ¨¡æ¿åŒ¹é…æ£€æµ‹ + SAM3åˆ†å‰² + SORTè¿½è¸ª

ç”¨æ³•:
    python3 scripts/integrated_traffic_sign_pipeline.py \
        --video data/D1_video_clips/your_video.mp4 \
        --output SAM3_output/traffic_signs_results.json
"""

import os
import sys
import json
import argparse
import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Any
import logging

# å¯¼å…¥ç°æœ‰æ¨¡å—
from traffic_sign_detector import TrafficSignDetector
from retrack_with_sort import SORTTracker  # å‡è®¾å¯ä»¥ä»ç°æœ‰è„šæœ¬å¯¼å…¥

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IntegratedTrafficSignPipeline:
    """é›†æˆäº¤é€šæ ‡å¿—æ£€æµ‹æµæ°´çº¿"""

    def __init__(self, signs_dir: str, detection_threshold: float = 0.7):
        """
        åˆå§‹åŒ–é›†æˆæµæ°´çº¿

        Args:
            signs_dir: äº¤é€šæ ‡å¿—å›¾åƒç›®å½•
            detection_threshold: æ£€æµ‹é˜ˆå€¼
        """
        self.signs_dir = signs_dir
        self.detection_threshold = detection_threshold

        # åˆå§‹åŒ–äº¤é€šæ ‡å¿—æ£€æµ‹å™¨
        self.sign_detector = TrafficSignDetector(signs_dir, detection_threshold)

        logger.info("é›†æˆäº¤é€šæ ‡å¿—æ£€æµ‹æµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")

    def process_video(self, video_path: str, output_path: str,
                     apply_sam3: bool = True, apply_sort: bool = True,
                     sample_rate: int = 5) -> Dict[str, Any]:
        """
        å¤„ç†è§†é¢‘çš„å®Œæ•´æµæ°´çº¿

        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            output_path: è¾“å‡ºè·¯å¾„
            apply_sam3: æ˜¯å¦åº”ç”¨SAM3åˆ†å‰²
            apply_sort: æ˜¯å¦åº”ç”¨SORTè¿½è¸ª
            sample_rate: é‡‡æ ·ç‡

        Returns:
            å¤„ç†ç»“æœ
        """
        logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")

        # ç¬¬ä¸€æ­¥: äº¤é€šæ ‡å¿—æ£€æµ‹
        logger.info("ğŸ” æ­¥éª¤1: äº¤é€šæ ‡å¿—æ£€æµ‹")
        detection_results = self.sign_detector.detect_video(
            video_path, output_path.replace('.json', '_detections.json'), sample_rate
        )

        raw_detections = detection_results['raw_detections']
        logger.info(f"æ£€æµ‹åˆ° {len(raw_detections)} ä¸ªäº¤é€šæ ‡å¿—")

        # ç¬¬äºŒæ­¥: åº”ç”¨SORTè¿½è¸ªå™¨
        tracked_results = None
        if apply_sort and raw_detections:
            logger.info("ğŸ”— æ­¥éª¤2: åº”ç”¨SORTè¿½è¸ªå™¨")
            tracked_results = self._apply_sort_tracking(
                video_path, raw_detections, output_path
            )

        # ç¬¬ä¸‰æ­¥: ç”Ÿæˆæœ€ç»ˆç»“æœ
        logger.info("ğŸ“¦ æ­¥éª¤3: ç”Ÿæˆæœ€ç»ˆç»“æœ")
        final_results = self._generate_final_results(
            detection_results, tracked_results, video_path, apply_sort
        )

        # ä¿å­˜æœ€ç»ˆç»“æœ
        self._save_final_results(final_results, output_path)

        logger.info("âœ… æµæ°´çº¿å¤„ç†å®Œæˆ")
        return final_results

    def _apply_sort_tracking(self, video_path: str, detections: List[Dict[str, Any]],
                           output_path: str) -> Dict[str, Any]:
        """
        åº”ç”¨SORTè¿½è¸ªå™¨

        Args:
            video_path: è§†é¢‘è·¯å¾„
            detections: æ£€æµ‹ç»“æœ
            output_path: è¾“å‡ºè·¯å¾„

        Returns:
            è¿½è¸ªç»“æœ
        """
        try:
            # è¿™é‡Œå¯ä»¥å¯¼å…¥ç°æœ‰çš„SORTè¿½è¸ªå™¨ä»£ç 
            # ç”±äºç°æœ‰è„šæœ¬æ¯”è¾ƒå¤æ‚ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬

            logger.info("åº”ç”¨SORTè¿½è¸ªå™¨åˆ°æ£€æµ‹ç»“æœ")

            # æŒ‰å¸§ç»„ç»‡æ£€æµ‹ç»“æœ
            frame_detections = {}
            for det in detections:
                frame_idx = det['frame']
                if frame_idx not in frame_detections:
                    frame_detections[frame_idx] = []
                frame_detections[frame_idx].append(det)

            # ç®€å•çš„è¿½è¸ªé€»è¾‘ (å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨SORT)
            tracked_results = self._simple_tracking(frame_detections)

            return tracked_results

        except Exception as e:
            logger.error(f"SORTè¿½è¸ªå¤±è´¥: {e}")
            return None

    def _simple_tracking(self, frame_detections: Dict[int, List[Dict[str, Any]]]) -> Dict[str, Any]:
        """
        ç®€å•çš„è¿½è¸ªå®ç° (æ›¿ä»£SORT)

        Args:
            frame_detections: æŒ‰å¸§ç»„ç»‡çš„æ£€æµ‹ç»“æœ

        Returns:
            è¿½è¸ªç»“æœ
        """
        tracks = {}
        track_id_counter = 0

        # æŒ‰å¸§æ’åº
        sorted_frames = sorted(frame_detections.keys())

        # ç®€å•çš„æœ€è¿‘é‚»åŒ¹é…è¿½è¸ª
        for i, frame_idx in enumerate(sorted_frames):
            detections = frame_detections[frame_idx]

            for det in detections:
                # ç®€å•åˆ†é…track ID (å®é™…åº”è¯¥ç”¨æ›´å¤æ‚çš„ç®—æ³•)
                det['track_id'] = track_id_counter
                tracks[track_id_counter] = {
                    'class': det['class'],
                    'start_frame': frame_idx,
                    'detections': [det]
                }
                track_id_counter += 1

        return {
            'tracks': tracks,
            'track_count': len(tracks)
        }

    def _generate_final_results(self, detection_results: Dict[str, Any],
                               tracked_results: Dict[str, Any],
                               video_path: str, use_tracking: bool) -> Dict[str, Any]:
        """
        ç”ŸæˆLabel Studioå…¼å®¹çš„æœ€ç»ˆç»“æœ

        Args:
            detection_results: æ£€æµ‹ç»“æœ
            tracked_results: è¿½è¸ªç»“æœ
            video_path: è§†é¢‘è·¯å¾„
            use_tracking: æ˜¯å¦ä½¿ç”¨è¿½è¸ª

        Returns:
            æœ€ç»ˆç»“æœ
        """
        raw_detections = detection_results['raw_detections']

        if not use_tracking or not tracked_results:
            # ä¸ä½¿ç”¨è¿½è¸ªçš„ç®€å•æ ¼å¼
            return self._create_simple_format(raw_detections, video_path)
        else:
            # ä½¿ç”¨è¿½è¸ªçš„æ ¼å¼
            return self._create_tracked_format(tracked_results, video_path)

    def _create_simple_format(self, detections: List[Dict[str, Any]], video_path: str) -> Dict[str, Any]:
        """åˆ›å»ºç®€å•æ ¼å¼çš„ç»“æœ"""
        # æŒ‰å¸§åˆ†ç»„
        frame_detections = {}
        for det in detections:
            frame_idx = det['frame']
            if frame_idx not in frame_detections:
                frame_detections[frame_idx] = []
            frame_detections[frame_idx].append(det)

        # åˆ›å»ºLabel Studioæ ¼å¼
        results = []

        for frame_idx, frame_dets in frame_detections.items():
            for det in frame_dets:
                x, y, w, h = det['bbox']

                # è½¬æ¢ä¸ºç›¸å¯¹åæ ‡ (è¿™é‡Œéœ€è¦æ ¹æ®å®é™…è§†é¢‘å°ºå¯¸è°ƒæ•´)
                rel_x = max(0, min(100, (x / 1920) * 100))  # å‡è®¾1920å®½åº¦
                rel_y = max(0, min(100, (y / 1080) * 100))  # å‡è®¾1080é«˜åº¦
                rel_width = max(0, min(100, (w / 1920) * 100))
                rel_height = max(0, min(100, (h / 1080) * 100))

                result_entry = {
                    "from_name": "box",
                    "to_name": "video",
                    "type": "videorectangle",
                    "value": {
                        "frames": [
                            {
                                "frame": frame_idx,
                                "x": rel_x,
                                "y": rel_y,
                                "width": rel_width,
                                "height": rel_height,
                                "time": frame_idx / 30.0  # å‡è®¾30fps
                            }
                        ],
                        "labels": [det['class']]
                    },
                    "id": f"detection_{frame_idx}_{det.get('track_id', 'unknown')}",
                    "score": det['confidence']
                }

                # å¦‚æœè¿˜æ²¡æœ‰resultsï¼Œåˆ›å»ºç¬¬ä¸€ä¸ªæ¡ç›®
                if not results:
                    results.append({
                        "data": {
                            "video": f"/data/local-files/?d={Path(video_path).name}"
                        },
                        "predictions": [{
                            "result": [],
                            "score": 0.0
                        }]
                    })

                results[0]["predictions"][0]["result"].append(result_entry)

        return {
            "label_studio_format": results,
            "detection_count": len(detections),
            "frame_count": len(frame_detections),
            "tracking_enabled": False
        }

    def _create_tracked_format(self, tracked_results: Dict[str, Any], video_path: str) -> Dict[str, Any]:
        """åˆ›å»ºå¸¦è¿½è¸ªçš„æ ¼å¼"""
        tracks = tracked_results['tracks']

        # åˆ›å»ºLabel Studioæ ¼å¼
        results = [{
            "data": {
                "video": f"/data/local-files/?d={Path(video_path).name}"
            },
            "predictions": [{
                "result": [],
                "score": 0.0
            }]
        }]

        # ä¸ºæ¯ä¸ªè½¨è¿¹åˆ›å»ºç»“æœ
        for track_id, track_info in tracks.items():
            if not track_info['detections']:
                continue

            # åˆ›å»ºè½¨è¿¹åºåˆ—
            sequence = []
            for det in track_info['detections']:
                x, y, w, h = det['bbox']

                # è½¬æ¢ä¸ºç›¸å¯¹åæ ‡
                rel_x = max(0, min(100, (x / 1920) * 100))
                rel_y = max(0, min(100, (y / 1080) * 100))
                rel_width = max(0, min(100, (w / 1920) * 100))
                rel_height = max(0, min(100, (h / 1080) * 100))

                frame_data = {
                    "frame": det['frame'],
                    "x": rel_x,
                    "y": rel_y,
                    "width": rel_width,
                    "height": rel_height,
                    "time": det['frame'] / 30.0,  # å‡è®¾30fps
                    "enabled": True
                }
                sequence.append(frame_data)

            # åˆ›å»ºè½¨è¿¹ç»“æœ
            track_result = {
                "from_name": "box",
                "to_name": "video",
                "type": "videorectangle",
                "value": {
                    "sequence": sequence,
                    "labels": [track_info['class']]
                },
                "id": f"track_{track_id}"
            }

            results[0]["predictions"][0]["result"].append(track_result)

        return {
            "label_studio_format": results,
            "track_count": len(tracks),
            "tracking_enabled": True
        }

    def _save_final_results(self, results: Dict[str, Any], output_path: str):
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        logger.info(f"ä¿å­˜æœ€ç»ˆç»“æœåˆ°: {output_path}")

        # ä¿å­˜Label Studioæ ¼å¼
        label_studio_path = output_path.replace('.json', '_label_studio.json')
        with open(label_studio_path, 'w', encoding='utf-8') as f:
            json.dump(results['label_studio_format'], f, indent=2, ensure_ascii=False)

        # ä¿å­˜å®Œæ•´ç»“æœ
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        logger.info(f"ç»“æœä¿å­˜å®Œæˆ:")
        logger.info(f"  - å®Œæ•´ç»“æœ: {output_path}")
        logger.info(f"  - Label Studioæ ¼å¼: {label_studio_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é›†æˆäº¤é€šæ ‡å¿—æ£€æµ‹æµæ°´çº¿')
    parser.add_argument('--video', required=True, help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', required=True, help='è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--signs-dir', default='signs/highres/png2560px/',
                       help='äº¤é€šæ ‡å¿—å›¾åƒç›®å½•')
    parser.add_argument('--threshold', type=float, default=0.7,
                       help='æ£€æµ‹é˜ˆå€¼')
    parser.add_argument('--sample-rate', type=int, default=5,
                       help='é‡‡æ ·ç‡ (æ¯Nå¸§å¤„ç†ä¸€æ¬¡)')
    parser.add_argument('--no-tracking', action='store_true',
                       help='ç¦ç”¨è¿½è¸ª')
    parser.add_argument('--debug', action='store_true',
                       help='å¯ç”¨è°ƒè¯•æ¨¡å¼')

    args = parser.parse_args()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    try:
        # åˆ›å»ºé›†æˆæµæ°´çº¿
        pipeline = IntegratedTrafficSignPipeline(
            args.signs_dir, args.threshold
        )

        # å¤„ç†è§†é¢‘
        results = pipeline.process_video(
            args.video, args.output,
            apply_sort=not args.no_tracking,
            sample_rate=args.sample_rate
        )

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        tracking_status = "å¯ç”¨" if not args.no_tracking else "ç¦ç”¨"
        if results.get('tracking_enabled', False):
            track_count = results.get('track_count', 0)
            print(f"\nğŸ¯ å¤„ç†å®Œæˆ!")
            print(f"è¿½è¸ªçŠ¶æ€: {tracking_status}")
            print(f"ç”Ÿæˆè½¨è¿¹æ•°: {track_count}")
        else:
            detection_count = results.get('detection_count', 0)
            frame_count = results.get('frame_count', 0)
            print(f"\nğŸ¯ å¤„ç†å®Œæˆ!")
            print(f"è¿½è¸ªçŠ¶æ€: {tracking_status}")
            print(f"æ£€æµ‹æ€»æ•°: {detection_count}")
            print(f"è¦†ç›–å¸§æ•°: {frame_count}")

        print(f"ç»“æœä¿å­˜åˆ°: {args.output}")

    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()