#!/usr/bin/env python3
"""
äº¤é€šæ ‡å¿—æ£€æµ‹ç»“æœå¯è§†åŒ–
æ”¯æŒæ£€æµ‹æ¡†ã€è¿½è¸ªIDã€ç±»åˆ«æ ‡ç­¾çš„æ˜¾ç¤º

ç”¨æ³•:
    python3 scripts/visualize_traffic_signs.py \
        --video data/D1_video_clips/your_video.mp4 \
        --detections traffic_signs_results.json \
        --output traffic_signs_annotated.mp4
"""

import os
import sys
import json
import argparse
import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Any, Tuple
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TrafficSignVisualizer:
    """äº¤é€šæ ‡å¿—æ£€æµ‹ç»“æœå¯è§†åŒ–å™¨"""

    def __init__(self):
        # é¢œè‰²æ˜ å°„ (BGRæ ¼å¼)
        self.colors = {
            'warning': (0, 255, 255),      # é»„è‰²
            'regulatory': (0, 0, 255),     # çº¢è‰²
            'information': (255, 0, 0),    # è“è‰²
            'distance': (0, 255, 0),       # ç»¿è‰²
            'default': (128, 128, 128)     # ç°è‰²
        }

        # ç±»åˆ«é¢œè‰²ç¼“å­˜
        self.class_colors = {}

    def _get_class_color(self, sign_class: str) -> Tuple[int, int, int]:
        """è·å–ç±»åˆ«å¯¹åº”çš„é¢œè‰²"""
        # åŸºäºç±»åˆ«åç§°åˆ†é…é¢œè‰²
        class_lower = sign_class.lower()

        if any(keyword in class_lower for keyword in ['warning', 'ahead', 'bend', 'cross']):
            return self.colors['warning']
        elif any(keyword in class_lower for keyword in ['stop', 'no_', 'limit', 'must']):
            return self.colors['regulatory']
        elif any(keyword in class_lower for keyword in ['lane', 'route', 'census']):
            return self.colors['information']
        elif 'distance' in class_lower or 'm_' in class_lower:
            return self.colors['distance']
        else:
            # ä¸ºå…¶ä»–ç±»åˆ«åˆ†é…éšæœºé¢œè‰²
            if sign_class not in self.class_colors:
                self.class_colors[sign_class] = (
                    np.random.randint(0, 255),
                    np.random.randint(0, 255),
                    np.random.randint(0, 255)
                )
            return self.class_colors[sign_class]

    def _get_short_class_name(self, sign_class: str, max_length: int = 20) -> str:
        """è·å–ç®€çŸ­çš„ç±»åˆ«åç§°ç”¨äºæ˜¾ç¤º"""
        # ç§»é™¤å¸¸è§çš„å‰ç¼€å’Œåç¼€
        name = sign_class.replace('_', ' ')

        # æˆªæ–­è¿‡é•¿çš„åç§°
        if len(name) > max_length:
            name = name[:max_length-3] + '...'

        return name

    def visualize_detections(self, video_path: str, detections_file: str,
                           output_path: str, show_confidence: bool = True,
                           show_track_id: bool = True, font_scale: float = 0.6):
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœ

        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            detections_file: æ£€æµ‹ç»“æœJSONæ–‡ä»¶
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            show_confidence: æ˜¯å¦æ˜¾ç¤ºç½®ä¿¡åº¦
            show_track_id: æ˜¯å¦æ˜¾ç¤ºè½¨è¿¹ID
            font_scale: å­—ä½“å¤§å°
        """
        logger.info(f"å¼€å§‹å¯è§†åŒ–æ£€æµ‹ç»“æœ")
        logger.info(f"è¾“å…¥è§†é¢‘: {video_path}")
        logger.info(f"æ£€æµ‹ç»“æœ: {detections_file}")
        logger.info(f"è¾“å‡ºè§†é¢‘: {output_path}")

        # åŠ è½½æ£€æµ‹ç»“æœ
        try:
            with open(detections_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception as e:
            logger.error(f"æ— æ³•åŠ è½½æ£€æµ‹ç»“æœæ–‡ä»¶: {e}")
            return

        # è§£ææ£€æµ‹ç»“æœ
        if 'detection_results' in data:
            # é›†æˆæµæ°´çº¿æ ¼å¼
            detection_results = data['detection_results']
            frame_detections = detection_results.get('frames', {})
        elif 'raw_detections' in data:
            # æ£€æµ‹å™¨æ ¼å¼
            raw_detections = data['raw_detections']
            frame_detections = {}
            for det in raw_detections:
                frame_idx = det['frame']
                if frame_idx not in frame_detections:
                    frame_detections[frame_idx] = []
                frame_detections[frame_idx].append(det)
        else:
            logger.error("æ— æ³•è¯†åˆ«çš„æ£€æµ‹ç»“æœæ ¼å¼")
            return

        logger.info(f"åŠ è½½äº† {len(frame_detections)} å¸§çš„æ£€æµ‹ç»“æœ")

        # æ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
            return

        # è·å–è§†é¢‘ä¿¡æ¯
        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        logger.info(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}FPS, {total_frames}å¸§")

        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # å­—ä½“è®¾ç½®
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_thickness = 2

        frame_idx = 0
        processed_frames = 0

        # å¤„ç†è§†é¢‘å¸§
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            # è·å–å½“å‰å¸§çš„æ£€æµ‹ç»“æœ
            current_detections = frame_detections.get(frame_idx, [])

            # ç»˜åˆ¶æ£€æµ‹ç»“æœ
            for det in current_detections:
                self._draw_detection(frame, det, font, font_scale, font_thickness,
                                   show_confidence, show_track_id)

            # æ·»åŠ å¸§ä¿¡æ¯
            info_text = f"Frame: {frame_idx}/{total_frames} | Detections: {len(current_detections)}"
            cv2.putText(frame, info_text, (10, 30), font, font_scale, (255, 255, 255), font_thickness)

            # å†™å…¥è¾“å‡ºè§†é¢‘
            out.write(frame)

            processed_frames += 1
            if processed_frames % 100 == 0:
                logger.info(f"å·²å¤„ç† {processed_frames} å¸§")

            frame_idx += 1

        # é‡Šæ”¾èµ„æº
        cap.release()
        out.release()

        logger.info(f"âœ… å¯è§†åŒ–å®Œæˆ!")
        logger.info(f"å¤„ç†äº† {processed_frames} å¸§")
        logger.info(f"è¾“å‡ºè§†é¢‘: {output_path}")

    def _draw_detection(self, frame: np.ndarray, detection: Dict[str, Any],
                       font, font_scale: float, font_thickness: int,
                       show_confidence: bool, show_track_id: bool):
        """
        ç»˜åˆ¶å•ä¸ªæ£€æµ‹ç»“æœ

        Args:
            frame: è§†é¢‘å¸§
            detection: æ£€æµ‹ç»“æœ
            font: å­—ä½“
            font_scale: å­—ä½“å¤§å°
            font_thickness: å­—ä½“ç²—ç»†
            show_confidence: æ˜¯å¦æ˜¾ç¤ºç½®ä¿¡åº¦
            show_track_id: æ˜¯å¦æ˜¾ç¤ºè½¨è¿¹ID
        """
        bbox = detection['bbox']
        confidence = detection['confidence']
        sign_class = detection['class']
        track_id = detection.get('track_id')

        x, y, w, h = bbox

        # è·å–é¢œè‰²
        color = self._get_class_color(sign_class)

        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)

        # å‡†å¤‡æ ‡ç­¾æ–‡æœ¬
        short_name = self._get_short_class_name(sign_class)
        label_parts = [short_name]

        if show_confidence:
            label_parts.append(f"{confidence:.2f}")

        if show_track_id and track_id is not None:
            label_parts.append(f"ID:{track_id}")

        label_text = " ".join(label_parts)

        # è®¡ç®—æ–‡æœ¬å¤§å°
        (text_width, text_height), baseline = cv2.getTextSize(label_text, font, font_scale, font_thickness)

        # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
        label_y = max(y, text_height + 10)
        cv2.rectangle(frame, (x, label_y - text_height - baseline - 5),
                     (x + text_width, label_y + baseline - 5), color, -1)

        # ç»˜åˆ¶æ–‡æœ¬
        cv2.putText(frame, label_text, (x, label_y - baseline),
                   font, font_scale, (255, 255, 255), font_thickness)

    def create_detection_summary(self, detections_file: str, output_path: str):
        """
        åˆ›å»ºæ£€æµ‹ç»“æœæ‘˜è¦

        Args:
            detections_file: æ£€æµ‹ç»“æœæ–‡ä»¶
            output_path: æ‘˜è¦å›¾åƒè¾“å‡ºè·¯å¾„
        """
        logger.info(f"åˆ›å»ºæ£€æµ‹ç»“æœæ‘˜è¦: {detections_file}")

        try:
            with open(detections_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except Exception as e:
            logger.error(f"æ— æ³•åŠ è½½æ£€æµ‹ç»“æœæ–‡ä»¶: {e}")
            return

        # ç»Ÿè®¡ä¿¡æ¯
        if 'raw_detections' in data:
            detections = data['raw_detections']
        else:
            logger.error("æ— æ³•æ‰¾åˆ°æ£€æµ‹ç»“æœæ•°æ®")
            return

        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        class_counts = {}
        for det in detections:
            sign_class = det['class']
            class_counts[sign_class] = class_counts.get(sign_class, 0) + 1

        if not class_counts:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æ£€æµ‹ç»“æœ")
            return

        # åˆ›å»ºæ‘˜è¦å›¾åƒ
        fig_height = max(600, len(class_counts) * 30 + 100)
        summary_img = np.ones((fig_height, 800, 3), dtype=np.uint8) * 255

        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        font_thickness = 2

        # æ ‡é¢˜
        title = "Traffic Sign Detection Summary"
        cv2.putText(summary_img, title, (200, 40), font, font_scale * 1.5, (0, 0, 0), font_thickness + 1)

        # ç»Ÿè®¡ä¿¡æ¯
        total_detections = len(detections)
        unique_classes = len(class_counts)
        info_text = f"Total Detections: {total_detections} | Unique Classes: {unique_classes}"
        cv2.putText(summary_img, info_text, (200, 80), font, font_scale, (0, 0, 0), font_thickness)

        # ç±»åˆ«ç»Ÿè®¡
        y_offset = 120
        for i, (sign_class, count) in enumerate(sorted(class_counts.items(), key=lambda x: x[1], reverse=True)):
            color = self._get_class_color(sign_class)
            short_name = self._get_short_class_name(sign_class, 35)

            # ç±»åˆ«åç§°
            text = f"{short_name}: {count}"
            cv2.putText(summary_img, text, (50, y_offset), font, font_scale, color, font_thickness)

            # ç»˜åˆ¶å°çŸ©å½¢ä½œä¸ºç¤ºä¾‹
            cv2.rectangle(summary_img, (750, y_offset - 15), (780, y_offset + 5), color, -1)

            y_offset += 30

        # ä¿å­˜æ‘˜è¦å›¾åƒ
        cv2.imwrite(output_path, summary_img)
        logger.info(f"æ‘˜è¦å›¾åƒä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='äº¤é€šæ ‡å¿—æ£€æµ‹ç»“æœå¯è§†åŒ–')
    parser.add_argument('--video', required=True, help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--detections', required=True, help='æ£€æµ‹ç»“æœJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', required=True, help='è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--summary', help='æ‘˜è¦å›¾åƒè¾“å‡ºè·¯å¾„ (å¯é€‰)')
    parser.add_argument('--no-confidence', action='store_true', help='ä¸æ˜¾ç¤ºç½®ä¿¡åº¦')
    parser.add_argument('--no-track-id', action='store_true', help='ä¸æ˜¾ç¤ºè½¨è¿¹ID')
    parser.add_argument('--font-scale', type=float, default=0.6, help='å­—ä½“å¤§å°')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')

    args = parser.parse_args()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    try:
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = TrafficSignVisualizer()

        # å¯è§†åŒ–æ£€æµ‹ç»“æœ
        visualizer.visualize_detections(
            args.video, args.detections, args.output,
            show_confidence=not args.no_confidence,
            show_track_id=not args.no_track_id,
            font_scale=args.font_scale
        )

        # åˆ›å»ºæ‘˜è¦å›¾åƒ (å¦‚æœæŒ‡å®š)
        if args.summary:
            visualizer.create_detection_summary(args.detections, args.summary)

        print(f"\nğŸ¯ å¯è§†åŒ–å®Œæˆ!")
        print(f"è¾“å‡ºè§†é¢‘: {args.output}")
        if args.summary:
            print(f"æ‘˜è¦å›¾åƒ: {args.summary}")

    except Exception as e:
        logger.error(f"å¯è§†åŒ–å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()