#!/usr/bin/env python3
"""
YOLO + ByteTrack è§†é¢‘ç›®æ ‡è¿½è¸ªè„šæœ¬
å¿«é€Ÿæ£€æµ‹å¹¶è¿½è¸ªè§†é¢‘ä¸­çš„ç›®æ ‡ï¼Œæ”¯æŒè·¨å¸§ ID ä¿æŒ

æ”¯æŒçš„ç›®æ ‡ç±»åˆ«ï¼ˆCOCOï¼‰ï¼š
- person (è¡Œäºº)
- car (æ±½è½¦)
- motorcycle (æ‘©æ‰˜è½¦)
- bicycle (è‡ªè¡Œè½¦)
- truck (å¡è½¦)
- bus (å…¬äº¤è½¦)
- traffic light (äº¤é€šç¯)
- stop sign (åœæ­¢æ ‡å¿—)
ç­‰ 80 ä¸ªç±»åˆ«

æ³¨æ„ï¼šCOCO æ¨¡å‹ä¸æ”¯æŒä¸€èˆ¬äº¤é€šæ ‡å¿—ï¼Œéœ€è¦ä½¿ç”¨ä¸“é—¨çš„æ¨¡å‹æˆ– SAM3
"""

import os
import sys
import json
import argparse
import cv2
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional
from collections import defaultdict

# COCO ç±»åˆ«æ˜ å°„ï¼ˆéƒ¨åˆ†ï¼‰
COCO_CLASSES = {
    0: 'person',
    1: 'bicycle',
    2: 'car',
    3: 'motorcycle',
    5: 'bus',
    7: 'truck',
    9: 'traffic light',
    11: 'stop sign',
}

# ä½ éœ€è¦çš„ç±»åˆ«
TARGET_CLASSES = {
    'person': 'è¡Œäºº',
    'car': 'æ±½è½¦',
    'motorcycle': 'æ‘©æ‰˜è½¦',
    'bicycle': 'è‡ªè¡Œè½¦',
    'bus': 'å…¬äº¤è½¦',
    'truck': 'å¡è½¦',
    'traffic light': 'äº¤é€šç¯',
    'stop sign': 'åœæ­¢æ ‡å¿—',
}

# é¢œè‰²æ˜ å°„ - æŒ‰ç±»åˆ«å›ºå®šé¢œè‰²ï¼Œä¸éš ID å˜åŒ–
COLORS = {
    'person': (0, 255, 0),       # ç»¿è‰²
    'car': (255, 0, 0),          # è“è‰²
    'motorcycle': (0, 0, 255),   # çº¢è‰²
    'bicycle': (255, 255, 0),    # é’è‰²
    'bus': (255, 0, 255),        # ç´«è‰²
    'truck': (0, 255, 255),      # é»„è‰²
    'traffic light': (128, 255, 0),
    'stop sign': (0, 128, 255),
}


def is_first_person_vehicle(box, frame_height, frame_width, cls_name):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºç¬¬ä¸€äººç§°è§†è§’çš„è½¦è¾†ï¼ˆéª‘è¡Œè€…è‡ªå·±çš„æ‘©æ‰˜è½¦/è‡ªè¡Œè½¦ï¼‰
    
    ç‰¹å¾ï¼š
    1. ä½äºç”»é¢åº•éƒ¨ï¼ˆy > 60% çš„é«˜åº¦ï¼‰
    2. é¢ç§¯è¾ƒå¤§ï¼ˆå ç”»é¢ > 15%ï¼‰
    3. æ˜¯æ‘©æ‰˜è½¦æˆ–è‡ªè¡Œè½¦
    """
    if cls_name not in ['motorcycle', 'bicycle']:
        return False
    
    x1, y1, x2, y2 = box
    box_height = y2 - y1
    box_width = x2 - x1
    box_area = box_height * box_width
    frame_area = frame_height * frame_width
    
    # æ¡ä»¶1ï¼šåº•éƒ¨åŒºåŸŸï¼ˆä¸­å¿ƒç‚¹åœ¨ä¸‹åŠéƒ¨åˆ†ï¼‰
    center_y = (y1 + y2) / 2
    is_bottom = center_y > frame_height * 0.5
    
    # æ¡ä»¶2ï¼šé¢ç§¯è¾ƒå¤§
    area_ratio = box_area / frame_area
    is_large = area_ratio > 0.1
    
    # æ¡ä»¶3ï¼šå®½åº¦è¾ƒå¤§ï¼ˆæ¨ªè·¨ç”»é¢ï¼‰
    width_ratio = box_width / frame_width
    is_wide = width_ratio > 0.3
    
    return is_bottom and (is_large or is_wide)


def run_yolo_tracking(
    video_path: str,
    output_json: str,
    target_classes: List[str] = None,
    model_name: str = "yolov8n.pt",
    confidence: float = 0.3,
    generate_video: bool = True,
    device: str = "mps"  # Mac ä½¿ç”¨ MPS
):
    """
    ä½¿ç”¨ YOLO + ByteTrack è¿›è¡Œè§†é¢‘ç›®æ ‡è¿½è¸ª
    
    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_json: è¾“å‡º JSON è·¯å¾„
        target_classes: è¦æ£€æµ‹çš„ç±»åˆ«åˆ—è¡¨
        model_name: YOLO æ¨¡å‹åç§°
        confidence: ç½®ä¿¡åº¦é˜ˆå€¼
        generate_video: æ˜¯å¦ç”Ÿæˆæ ‡æ³¨è§†é¢‘
        device: è®¡ç®—è®¾å¤‡
    """
    from ultralytics import YOLO
    
    print(f"ğŸ¬ åŠ è½½è§†é¢‘: {video_path}")
    
    # è·å–è§†é¢‘ä¿¡æ¯
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()
    
    print(f"   å¸§ç‡: {fps:.1f}, æ€»å¸§æ•°: {frame_count}, åˆ†è¾¨ç‡: {width}x{height}")
    print(f"   è§†é¢‘æ—¶é•¿: {frame_count/fps:.1f} ç§’")
    
    # åŠ è½½ YOLO æ¨¡å‹
    print(f"ğŸ”§ åŠ è½½ YOLO æ¨¡å‹: {model_name}")
    model = YOLO(model_name)
    
    # è®¾ç½®è¦æ£€æµ‹çš„ç±»åˆ«
    if target_classes:
        # è·å–ç±»åˆ« ID
        class_names = model.names
        class_ids = [k for k, v in class_names.items() if v in target_classes]
        print(f"ğŸ·ï¸ æ£€æµ‹ç±»åˆ«: {target_classes}")
    else:
        class_ids = None
        print(f"ğŸ·ï¸ æ£€æµ‹æ‰€æœ‰ç±»åˆ«")
    
    # è¿è¡Œè¿½è¸ª
    print(f"ğŸ”„ å¼€å§‹è¿½è¸ª...")
    results = model.track(
        source=video_path,
        tracker="bytetrack.yaml",  # ä½¿ç”¨ ByteTrack
        conf=confidence,
        classes=class_ids,
        device=device,
        stream=True,  # æµå¼å¤„ç†ï¼ŒèŠ‚çœå†…å­˜
        verbose=False
    )
    
    # æ”¶é›†è¿½è¸ªç»“æœ
    all_tracks = defaultdict(lambda: {"class": None, "frames": {}})
    
    # å‡†å¤‡è¾“å‡ºè§†é¢‘
    video_output_path = None
    video_writer = None
    temp_video_path = None
    
    if generate_video:
        video_output_path = output_json.replace('.json', '_annotated.mp4')
        temp_video_path = output_json.replace('.json', '_temp.avi')
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        video_writer = cv2.VideoWriter(temp_video_path, fourcc, fps, (width, height))
    
    frame_idx = 0
    for result in results:
        # è·å–å½“å‰å¸§
        frame = result.orig_img.copy()
        
        # å¤„ç†æ£€æµ‹ç»“æœ
        if result.boxes is not None and len(result.boxes) > 0:
            boxes = result.boxes
            
            for i in range(len(boxes)):
                # è·å–è¾¹ç•Œæ¡†
                xyxy = boxes.xyxy[i].cpu().numpy()
                x1, y1, x2, y2 = xyxy
                
                # è·å–ç±»åˆ«
                cls_id = int(boxes.cls[i].cpu().numpy())
                cls_name = model.names[cls_id]
                
                # è·å–ç½®ä¿¡åº¦
                conf = float(boxes.conf[i].cpu().numpy())
                
                # è·å–è¿½è¸ª ID
                if boxes.id is not None:
                    track_id = int(boxes.id[i].cpu().numpy())
                else:
                    track_id = i  # å¦‚æœæ²¡æœ‰è¿½è¸ª IDï¼Œä½¿ç”¨ç´¢å¼•
                
                # è¿‡æ»¤ç¬¬ä¸€äººç§°è§†è§’çš„è½¦è¾†ï¼ˆéª‘è¡Œè€…è‡ªå·±çš„æ‘©æ‰˜è½¦ï¼‰
                if is_first_person_vehicle((x1, y1, x2, y2), height, width, cls_name):
                    continue  # è·³è¿‡ä¸æ ‡æ³¨
                
                # ä¿å­˜è¿½è¸ªæ•°æ®
                track_key = f"{cls_name}_{track_id}"
                all_tracks[track_key]["class"] = cls_name
                all_tracks[track_key]["track_id"] = track_id
                all_tracks[track_key]["frames"][frame_idx] = {
                    "x": float(x1) / width * 100,
                    "y": float(y1) / height * 100,
                    "width": float(x2 - x1) / width * 100,
                    "height": float(y2 - y1) / height * 100,
                    "confidence": conf,
                    "time": frame_idx / fps
                }
                
                # åœ¨å¸§ä¸Šç»˜åˆ¶ - é¢œè‰²æŒ‰ç±»åˆ«å›ºå®š
                if video_writer is not None:
                    color = COLORS.get(cls_name, (0, 255, 0))
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    
                    # ç»˜åˆ¶æ ‡ç­¾ï¼ˆæ˜¾ç¤ºç±»åˆ«å’Œ IDï¼‰
                    label = f"{cls_name} #{track_id}"
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    font_scale = 0.5
                    thickness = 1
                    (tw, th), _ = cv2.getTextSize(label, font, font_scale, thickness)
                    
                    cv2.rectangle(frame, (int(x1), int(y1) - th - 6), 
                                  (int(x1) + tw + 6, int(y1)), color, -1)
                    cv2.putText(frame, label, (int(x1) + 3, int(y1) - 3), 
                                font, font_scale, (255, 255, 255), thickness)
        
        # å†™å…¥å¸§å·
        if video_writer is not None:
            cv2.putText(frame, f"Frame: {frame_idx}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
            video_writer.write(frame)
        
        frame_idx += 1
        if frame_idx % 100 == 0:
            print(f"   å·²å¤„ç† {frame_idx}/{frame_count} å¸§...")
    
    print(f"   å¤„ç†å®Œæˆï¼Œå…± {frame_idx} å¸§")
    
    # å…³é—­è§†é¢‘å†™å…¥
    if video_writer is not None:
        video_writer.release()
        
        # ä½¿ç”¨ ffmpeg ä¼˜åŒ–ç¼–ç 
        if temp_video_path and os.path.exists(temp_video_path):
            print("ğŸ”„ æ­£åœ¨ä¼˜åŒ–è§†é¢‘ç¼–ç ...")
            import subprocess
            try:
                cmd = [
                    'ffmpeg', '-y', '-i', temp_video_path,
                    '-c:v', 'libx264', '-preset', 'fast', '-crf', '23',
                    '-pix_fmt', 'yuv420p',
                    video_output_path
                ]
                subprocess.run(cmd, capture_output=True, check=True)
                os.remove(temp_video_path)
                print("   è§†é¢‘ç¼–ç ä¼˜åŒ–å®Œæˆ")
            except (subprocess.CalledProcessError, FileNotFoundError):
                import shutil
                shutil.move(temp_video_path, video_output_path)
    
    # è½¬æ¢ä¸º Label Studio æ ¼å¼
    ls_results = []
    for track_key, track_data in all_tracks.items():
        frames_data = track_data["frames"]
        if not frames_data:
            continue
        
        sequence = []
        for fidx, data in sorted(frames_data.items()):
            sequence.append({
                "frame": fidx,
                "x": data["x"],
                "y": data["y"],
                "width": data["width"],
                "height": data["height"],
                "rotation": 0,
                "time": data["time"],
                "enabled": True
            })
        
        if sequence:
            ls_results.append({
                "from_name": "box",
                "to_name": "video",
                "type": "videorectangle",
                "value": {
                    "sequence": sequence,
                    "labels": [track_data["class"]]
                },
                "id": track_key
            })
    
    # ä¿å­˜ JSON
    output_data = [{
        "data": {
            "video": f"/data/local-files/?d={os.path.basename(video_path)}"
        },
        "predictions": [{
            "result": ls_results,
            "model_version": f"YOLO-{model_name}-ByteTrack"
        }]
    }]
    
    os.makedirs(os.path.dirname(os.path.abspath(output_json)), exist_ok=True)
    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    # ç»Ÿè®¡
    class_counts = defaultdict(int)
    for track_key, track_data in all_tracks.items():
        class_counts[track_data["class"]] += 1
    
    print(f"\nâœ… JSON ç»“æœå·²ä¿å­˜åˆ°: {output_json}")
    print(f"   å…±è¿½è¸ªåˆ° {len(all_tracks)} ä¸ªç›®æ ‡:")
    for cls, count in sorted(class_counts.items()):
        print(f"      - {cls}: {count} ä¸ª")
    
    if video_output_path:
        print(f"âœ… æ ‡æ³¨è§†é¢‘å·²ä¿å­˜åˆ°: {video_output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="YOLO + ByteTrack è§†é¢‘ç›®æ ‡è¿½è¸ª"
    )
    parser.add_argument(
        "video_path",
        help="è¾“å…¥è§†é¢‘è·¯å¾„"
    )
    parser.add_argument(
        "--output", "-o",
        default="YOLO_output/tracking_result.json",
        help="è¾“å‡º JSON è·¯å¾„"
    )
    parser.add_argument(
        "--classes", "-c",
        nargs="+",
        default=["person", "car", "motorcycle", "bicycle", "bus", "truck", "traffic light", "stop sign"],
        help="è¦æ£€æµ‹çš„ç±»åˆ«"
    )
    parser.add_argument(
        "--model", "-m",
        default="yolov8n.pt",
        choices=["yolov8n.pt", "yolov8s.pt", "yolov8m.pt", "yolov8l.pt", "yolov8x.pt"],
        help="YOLO æ¨¡å‹ (n=æœ€å¿«, x=æœ€å‡†)"
    )
    parser.add_argument(
        "--confidence",
        type=float,
        default=0.3,
        help="ç½®ä¿¡åº¦é˜ˆå€¼"
    )
    parser.add_argument(
        "--device",
        default="mps",
        choices=["mps", "cpu", "cuda"],
        help="è®¡ç®—è®¾å¤‡"
    )
    parser.add_argument(
        "--no-video",
        action="store_true",
        help="ä¸ç”Ÿæˆæ ‡æ³¨è§†é¢‘"
    )
    
    args = parser.parse_args()
    
    if not os.path.exists(args.video_path):
        print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {args.video_path}")
        sys.exit(1)
    
    run_yolo_tracking(
        video_path=args.video_path,
        output_json=args.output,
        target_classes=args.classes,
        model_name=args.model,
        confidence=args.confidence,
        generate_video=not args.no_video,
        device=args.device
    )


if __name__ == "__main__":
    main()

