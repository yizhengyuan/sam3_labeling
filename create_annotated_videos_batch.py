#!/usr/bin/env python3
"""
æ‰¹é‡åˆ›å»ºå¸¦æ ‡æ³¨æ¡†çš„å¯è§†åŒ–è§†é¢‘
"""

import cv2
import json
import os
from pathlib import Path
import sys
import numpy as np

def create_annotated_video(video_path, json_path, output_path):
    """åˆ›å»ºå¸¦æ ‡æ³¨æ¡†çš„è§†é¢‘"""
    
    # è¯»å–æ ‡æ³¨
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    results = data[0]['predictions'][0]['result']
    
    # æŒ‰å¸§å·ç»„ç»‡ï¼ˆä¸åšæ’å€¼ï¼‰
    frame_annotations = {}
    for result in results:
        frame_num = result['value']['frame']
        if frame_num not in frame_annotations:
            frame_annotations[frame_num] = []
        frame_annotations[frame_num].append(result)
    
    # ä¸­è‹±æ–‡æ˜ å°„
    category_mapping = {
        "æ±½è½¦": "Car",
        "äº¤é€šæ ‡å¿—": "Traffic Sign",
        "æ‘©æ‰˜è½¦": "Motorcycle",
        "è¡Œäºº": "Pedestrian",
        "è‡ªè¡Œè½¦": "Bicycle",
        "æ–½å·¥åŒºåŸŸ": "Construction",
    }
    
    # é¢œè‰²
    colors = {
        "Car": (66, 165, 245),           # è“è‰²
        "Traffic Sign": (156, 39, 176),   # ç´«è‰²
        "Motorcycle": (102, 187, 106),    # ç»¿è‰²
        "Pedestrian": (255, 112, 67),     # æ©™è‰²
        "Bicycle": (255, 193, 7),         # é»„è‰²
        "Construction": (255, 87, 34),    # æ·±æ©™è‰²
    }
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        return False
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_count = 0
    labeled_frames = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # åªç»˜åˆ¶æœ‰AIæ£€æµ‹çš„å¸§
        if frame_count in frame_annotations:
            labeled_frames += 1
            
            for result in frame_annotations[frame_count]:
                value = result['value']
                
                # 1. å¤„ç†çŸ©å½¢æ¡†
                if 'rectanglelabels' in value:
                    category_cn = value['rectanglelabels'][0]
                    category_en = category_mapping.get(category_cn, category_cn)
                    
                    x = int(value['x'] * width / 100)
                    y = int(value['y'] * height / 100)
                    w = int(value['width'] * width / 100)
                    h = int(value['height'] * height / 100)
                    
                    color = colors.get(category_en, (255, 255, 255))
                    
                    # ç»˜åˆ¶çŸ©å½¢æ¡†
                    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
                    
                    # ç»˜åˆ¶æ ‡ç­¾
                    label = category_en
                    (label_w, label_h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
                    cv2.rectangle(frame, (x, y - label_h - 8), (x + label_w + 5, y), color, -1)
                    cv2.putText(frame, label, (x + 2, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                # 2. å¤„ç†å¤šè¾¹å½¢ (SAM3)
                elif 'polygonlabels' in value:
                    category_cn = value['polygonlabels'][0]
                    category_en = category_mapping.get(category_cn, category_cn)
                    points = value['points'] # [[x1, y1], [x2, y2], ...] (0-100)
                    
                    # è½¬æ¢åæ ‡
                    pts = []
                    for p in points:
                        px = int(p[0] * width / 100)
                        py = int(p[1] * height / 100)
                        pts.append([px, py])
                    
                    pts = np.array(pts, np.int32)
                    pts = pts.reshape((-1, 1, 2))
                    
                    color = colors.get(category_en, (255, 255, 255))
                    
                    # ç»˜åˆ¶å¤šè¾¹å½¢è½®å»“
                    cv2.polylines(frame, [pts], True, color, 2)
                    
                    # ç»˜åˆ¶åŠé€æ˜å¡«å……
                    overlay = frame.copy()
                    cv2.fillPoly(overlay, [pts], color)
                    cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)
            
            # çŠ¶æ€ä¿¡æ¯ï¼ˆç»¿è‰²ï¼‰
            num_objs = len(frame_annotations[frame_count])
            info_text = f"Frame: {frame_count}/{total_frames} | AI | Objects: {num_objs}"
            cv2.putText(frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            # æ— æ ‡æ³¨å¸§ï¼ˆç°è‰²æç¤ºï¼‰
            info_text = f"Frame: {frame_count}/{total_frames}"
            cv2.putText(frame, info_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (128, 128, 128), 2)
        
        # SR:5æ ‡è®°
        cv2.putText(frame, "SR:5", (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)
        
        out.write(frame)
        frame_count += 1
    
    cap.release()
    out.release()
    
    return True


def main():
    """æ‰¹é‡å¤„ç†"""
    
    print("=" * 70)
    print("ğŸ¬ æ‰¹é‡åˆ›å»ºå¸¦æ ‡æ³¨æ¡†çš„å¯è§†åŒ–è§†é¢‘")
    print("=" * 70)
    print()
    
    json_dir = "labels/batch_output/json"
    video_dir = "data/D1_video_clips"
    output_dir = "labels/batch_output/videos"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–æ‰€æœ‰JSONæ–‡ä»¶
    json_files = sorted(Path(json_dir).glob("*_sr5.json"))
    
    total = len(json_files)
    success = 0
    failed = 0
    
    print(f"ğŸ“Š æ‰¾åˆ° {total} ä¸ªæ ‡æ³¨æ–‡ä»¶")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print()
    
    for i, json_path in enumerate(json_files, 1):
        # æå–è§†é¢‘æ–‡ä»¶å
        basename = json_path.stem.replace("_sr5", "")
        video_path = os.path.join(video_dir, f"{basename}.mp4")
        output_path = os.path.join(output_dir, f"{basename}_annotated.mp4")
        
        print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print(f"[{i}/{total}] {basename}")
        print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        
        if not os.path.exists(video_path):
            print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            failed += 1
            continue
        
        if os.path.exists(output_path):
            print(f"â­ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {output_path}")
            success += 1
            continue
        
        print(f"   è§†é¢‘: {video_path}")
        print(f"   æ ‡æ³¨: {json_path}")
        print(f"   è¾“å‡º: {output_path}")
        print()
        
        # åˆ›å»ºè§†é¢‘
        if create_annotated_video(str(video_path), str(json_path), output_path):
            file_size = Path(output_path).stat().st_size / 1024 / 1024
            print(f"   âœ… æˆåŠŸï¼æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            success += 1
        else:
            print(f"   âŒ å¤±è´¥")
            failed += 1
        
        print()
    
    print("=" * 70)
    print("âœ… æ‰¹é‡åˆ›å»ºå®Œæˆï¼")
    print("=" * 70)
    print()
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"  - æ€»æ•°: {total}")
    print(f"  - æˆåŠŸ: {success}")
    print(f"  - å¤±è´¥: {failed}")
    print()
    print(f"ğŸ“ å¯è§†åŒ–è§†é¢‘ä½ç½®: {output_dir}/")
    print()
    print("ğŸ¬ æŸ¥çœ‹è§†é¢‘:")
    print(f"   open {output_dir}")
    print()


if __name__ == "__main__":
    main()


