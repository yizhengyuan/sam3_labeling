{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¬ SAM3 è§†é¢‘ç›®æ ‡è¿½è¸ª (Google Colab)\n",
        "\n",
        "æœ¬ Notebook ä½¿ç”¨ SAM3 åœ¨ GPU ä¸Šè¿›è¡Œè§†é¢‘ç›®æ ‡è¿½è¸ªï¼Œæ”¯æŒï¼š\n",
        "- æ–‡æœ¬æç¤ºæ£€æµ‹ä»»æ„ç›®æ ‡\n",
        "- è·¨å¸§ç›®æ ‡è¿½è¸ªï¼ˆID ä¿æŒï¼‰\n",
        "- æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘\n",
        "\n",
        "**è¿è¡Œå‰è¯·ç¡®ä¿**ï¼š\n",
        "1. é€‰æ‹© GPU è¿è¡Œæ—¶ï¼š`è¿è¡Œæ—¶ -> æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ -> T4 GPU`\n",
        "2. å·²ç™»å½• Hugging Face å¹¶æœ‰ SAM3 è®¿é—®æƒé™\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1ï¸âƒ£ æ£€æŸ¥ GPU å¹¶å®‰è£…ä¾èµ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ£€æŸ¥ GPU\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®‰è£… SAM3 å’Œä¾èµ–\n",
        "!pip install git+https://github.com/facebookresearch/sam3.git\n",
        "!pip install opencv-python matplotlib scikit-learn tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç™»å½• Hugging Faceï¼ˆéœ€è¦ SAM3 è®¿é—®æƒé™ï¼‰\n",
        "from huggingface_hub import login\n",
        "\n",
        "# æ–¹æ³•1ï¼šäº¤äº’å¼ç™»å½•\n",
        "login()\n",
        "\n",
        "# æ–¹æ³•2ï¼šä½¿ç”¨ tokenï¼ˆå–æ¶ˆæ³¨é‡Šå¹¶å¡«å…¥ä½ çš„ tokenï¼‰\n",
        "# login(token=\"your_hf_token_here\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2ï¸âƒ£ æŒ‚è½½ Google Drive å¹¶ä¸Šä¼ è§†é¢‘\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# åˆ›å»ºå·¥ä½œç›®å½•\n",
        "import os\n",
        "WORK_DIR = \"/content/drive/MyDrive/SAM3_Tracking\"\n",
        "os.makedirs(f\"{WORK_DIR}/videos\", exist_ok=True)\n",
        "os.makedirs(f\"{WORK_DIR}/outputs\", exist_ok=True)\n",
        "\n",
        "print(f\"âœ… è¯·å°†è§†é¢‘ä¸Šä¼ åˆ°: {WORK_DIR}/videos/\")\n",
        "print(f\"âœ… è¾“å‡ºå°†ä¿å­˜åˆ°: {WORK_DIR}/outputs/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ—å‡ºå·²ä¸Šä¼ çš„è§†é¢‘\n",
        "videos = [f for f in os.listdir(f\"{WORK_DIR}/videos\") if f.endswith('.mp4')]\n",
        "print(f\"æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘:\")\n",
        "for v in videos[:10]:\n",
        "    print(f\"  - {v}\")\n",
        "if len(videos) > 10:\n",
        "    print(f\"  ... è¿˜æœ‰ {len(videos) - 10} ä¸ª\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3ï¸âƒ£ åŠ è½½ SAM3 æ¨¡å‹\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from sam3 import build_sam3_video_predictor\n",
        "\n",
        "# æ„å»ºè§†é¢‘é¢„æµ‹å™¨ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼‰\n",
        "print(\"æ­£åœ¨åŠ è½½ SAM3 æ¨¡å‹...\")\n",
        "predictor = build_sam3_video_predictor(device=\"cuda\")\n",
        "print(\"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4ï¸âƒ£ å®šä¹‰è¿½è¸ªå‡½æ•°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "\n",
        "def track_video_with_sam3(predictor, video_path, text_prompts, output_json, confidence_threshold=0.3):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨ SAM3 è¿½è¸ªè§†é¢‘ä¸­çš„ç›®æ ‡\n",
        "    \n",
        "    Args:\n",
        "        predictor: SAM3 è§†é¢‘é¢„æµ‹å™¨\n",
        "        video_path: è¾“å…¥è§†é¢‘è·¯å¾„\n",
        "        text_prompts: æ–‡æœ¬æç¤ºåˆ—è¡¨ï¼Œå¦‚ [\"car\", \"person\", \"traffic sign\"]\n",
        "        output_json: è¾“å‡º JSON è·¯å¾„\n",
        "        confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼\n",
        "    \"\"\"\n",
        "    print(f\"\\nğŸ¬ å¤„ç†è§†é¢‘: {video_path}\")\n",
        "    print(f\"ğŸ·ï¸ æ£€æµ‹ç›®æ ‡: {text_prompts}\")\n",
        "    \n",
        "    # è·å–è§†é¢‘ä¿¡æ¯\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    cap.release()\n",
        "    \n",
        "    print(f\"   è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps:.1f}fps, {frame_count}å¸§, {frame_count/fps:.1f}ç§’\")\n",
        "    \n",
        "    # åˆå§‹åŒ–è§†é¢‘çŠ¶æ€\n",
        "    state = predictor.init_state(video_path=video_path)\n",
        "    \n",
        "    all_tracks = {}  # {(prompt, obj_id): [(frame_idx, box, score), ...]}\n",
        "    \n",
        "    # å¯¹æ¯ä¸ªæ–‡æœ¬æç¤ºè¿›è¡Œè¿½è¸ª\n",
        "    for prompt in text_prompts:\n",
        "        print(f\"\\n   ğŸ“ è¿½è¸ª: '{prompt}'\")\n",
        "        \n",
        "        # é‡ç½®çŠ¶æ€\n",
        "        predictor.reset_state(state)\n",
        "        \n",
        "        # åœ¨ç¬¬ä¸€å¸§æ·»åŠ æ–‡æœ¬æç¤º\n",
        "        frame_idx, obj_ids, masks = predictor.add_new_text(\n",
        "            inference_state=state,\n",
        "            frame_idx=0,\n",
        "            text=prompt\n",
        "        )\n",
        "        \n",
        "        print(f\"      ç¬¬ä¸€å¸§æ£€æµ‹åˆ° {len(obj_ids)} ä¸ªç›®æ ‡\")\n",
        "        \n",
        "        # ä¼ æ’­è¿½è¸ªåˆ°æ‰€æœ‰å¸§\n",
        "        for frame_idx, obj_ids, video_res_masks in predictor.propagate_in_video(state):\n",
        "            # ä» mask è®¡ç®— bounding box\n",
        "            for i, obj_id in enumerate(obj_ids):\n",
        "                if i < len(video_res_masks):\n",
        "                    mask = video_res_masks[i].cpu().numpy().squeeze()\n",
        "                    \n",
        "                    # è®¡ç®— bounding box\n",
        "                    if mask.any():\n",
        "                        rows = np.any(mask, axis=1)\n",
        "                        cols = np.any(mask, axis=0)\n",
        "                        y1, y2 = np.where(rows)[0][[0, -1]]\n",
        "                        x1, x2 = np.where(cols)[0][[0, -1]]\n",
        "                        \n",
        "                        key = (prompt, obj_id)\n",
        "                        if key not in all_tracks:\n",
        "                            all_tracks[key] = []\n",
        "                        \n",
        "                        all_tracks[key].append({\n",
        "                            \"frame\": frame_idx,\n",
        "                            \"x\": float(x1) / width * 100,\n",
        "                            \"y\": float(y1) / height * 100,\n",
        "                            \"width\": float(x2 - x1) / width * 100,\n",
        "                            \"height\": float(y2 - y1) / height * 100,\n",
        "                            \"time\": frame_idx / fps\n",
        "                        })\n",
        "        \n",
        "        print(f\"      è¿½è¸ªå®Œæˆ\")\n",
        "    \n",
        "    # è½¬æ¢ä¸º Label Studio æ ¼å¼\n",
        "    ls_results = []\n",
        "    \n",
        "    for (prompt, obj_id), track in all_tracks.items():\n",
        "        if track:\n",
        "            sequence = sorted(track, key=lambda x: x[\"frame\"])\n",
        "            for item in sequence:\n",
        "                item[\"enabled\"] = True\n",
        "                item[\"rotation\"] = 0\n",
        "            \n",
        "            ls_results.append({\n",
        "                \"from_name\": \"box\",\n",
        "                \"to_name\": \"video\",\n",
        "                \"type\": \"videorectangle\",\n",
        "                \"value\": {\n",
        "                    \"sequence\": sequence,\n",
        "                    \"labels\": [prompt]\n",
        "                },\n",
        "                \"id\": f\"{prompt}_{obj_id}\"\n",
        "            })\n",
        "    \n",
        "    # ä¿å­˜ JSON\n",
        "    output_data = [{\n",
        "        \"data\": {\n",
        "            \"video\": f\"/data/local-files/?d={os.path.basename(video_path)}\"\n",
        "        },\n",
        "        \"predictions\": [{\n",
        "            \"result\": ls_results,\n",
        "            \"model_version\": \"SAM3-VideoPredictor\"\n",
        "        }]\n",
        "    }]\n",
        "    \n",
        "    with open(output_json, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"\\nâœ… JSON å·²ä¿å­˜: {output_json}\")\n",
        "    print(f\"   å…±è¿½è¸ªåˆ° {len(ls_results)} ä¸ªç›®æ ‡è½¨è¿¹\")\n",
        "    \n",
        "    return output_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5ï¸âƒ£ è¿è¡Œè¿½è¸ªï¼ˆå•ä¸ªè§†é¢‘æµ‹è¯•ï¼‰\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
